\section{Real-time Communication}

%% 
%% Leave first page empty
\thispagestyle{empty}

Real-time Communication is defined as any method of communication where users can exchange data packets (e.g media, text, etc.) with low latency in both direction. The purpose of RTC is widely seen as a way to communicate between people. This is done in a two-way scenario where both users are senders and receivers of media packets, live video is a one-way configuration with one unique source of data and one or multiple receivers. In the first RTC configuration, latency is very important in order to achieve good quality for bidirectional communication between both users whereas the live scenario can tolerate some latency in the link. In two-way communication data can be transmitted using multiple topologies, they are either peer-to-peer or using a centralized relay. 

Some other ways of transmitting data include multicast or broadcast. In the development of this thesis we do not study multicast and broadcast streaming.

\begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{./figures/P2P.pdf}
      \caption[Real time communication between two users over the Internet]{Real time communication between two users over the Internet.}
	\label{fig:RTC}
\end{figure}

Figure~\ref{fig:RTC} shows an RTC scenario for two users, the technology providing the communication may differ in each situation but the goal is always the same. 

RTC has a characteristic that is always common in all technologies, there must be a signaling or agreement between the two entities, either with the central node or with the other user. This procedure is used by the protocols to check the capabilities of the two entities before proceeding to send the media. The signaling channel is used to negotiate the codec agreement and NAT traversal methods that are used at the same time as all the multiple features that will be enabled in the new session, making it crucial to configure the media and data to be transmitted.

On the other hand, once signaling is done data starts to flow to the receiver, this stream may include media (audio or video) and different types of data (e.g binary, text, etc.). During the transmission we may also require some extra signaling messages to be exchanged in order to maintain the path or adapt the constraints to the present network conditions, at the same time, features might change during the session. 

%Those  messages are used for Offer/Answer model, congestion control adaptation or NAT traversal issues.

%Some RTC technologies and protocols are: telephony, mobile phone communication, radio, instant messaging (IM) \nomenclature{IM}{Instant Messaging}, Voice over IP (VoIP) \nomenclature{VoIP}{Voice over IP},  Video and Voice over IP (VVoIP) \nomenclature{VVoIP}{Video and Voice over IP}, Internet Relay Chat (IRC) \nomenclature{IRC}{Internet Relay Chat} and videoconferencing. 

%All the previous ways of communication work in real time and rely in Figure~\ref{fig:RTC} topology but with different technologies (e.g SIP, RTFMP and WebRTC). In this thesis we manly work with Internet RTC using media and data.
%Web Real-Time Communication is a technology that builds P2P applications by using a defined JavaScript API. The first announcement went public in a WG of the World Wide Web Consortium (W3C) in May 2011~\cite{webrtcW3cgroup} and started the official mailing list in April 2011~\cite{welcomeW3C}. During the first stage of discussion, the main goal was to define a public draft for the version 1 API implementation and a route timeline with the goal to publish the first version by March 2013. The first public draft of W3C came public the 27th of October 2011~\cite{originalW3Cdraft}. During this first W3C draft, only media (audio and video) could be sent over the network to other peers, it is focused in the way browsers are able to access the media devices without using any plugin or external software.
%
%Alongside to the W3C working group, the WebRTC project also joined the IETF with a WG in May 2011~\cite{webrtcIETFgroup} with the first public announcement charter done the 3th of May 2011~\cite{webrtcIETFcharter}. Milestones of the WG initially marked December 2011 as deadline to provide the information and elements required to the W3C for the API design input. On the other side, the main goals of the WG covered the definition of the communication model, session management, security, NAT traversal solution, media formats, codec agreement and data transport~\cite{webrtcIETFcharter}.
%
%One  of the most important steps during the process of standardization came the 1st of June 2011 when Google publicly released the source code of their API implementation~\cite{haraldpublicWebRTC}. 
%
%During all this period both WGs have been working alongside to provide a reliable solution to enable cross-platform applications to perform media and data P2P transfer over the browser in a plugin-free environment. The first final version of the WebRTC API is to be published at the end of 2013.
%
%Some alternatives are available to the WebRTC concept, considering the global architecture of WebRTC, Session Initiation Protocol (SIP) and Secure Real-Time Media Flow Protocol (RTMFP) are similar approaches to the same solution.

\subsection{Session Initiation Protocol (SIP)}

SIP \nomenclature{SIP}{Session Initiation Protocol} is a protocol used to create, modify and terminate multimedia sessions. This protocol features real-time communication between different peers with multiple optional extensions, those extensions allow the usage of instant messages or subscriptions to different events. SIP final Request for Comments (RFC) \nomenclature{RFC}{Request for Comments} was published in June 2004, this document describes the original functionalities and mechanisms of SIP~\cite{sipRFC}.

Other features of SIP is the ability to invite participants to already existing sessions in order to build multicast conferences. SIP also gives support for name redirection being a federated protocol regardless of the user network location.

The process of SIP includes the user location, availability, media capabilities, setup of the session and management of itself. On the other side, SIP can also be defined a suite of tools that are built together with other existing protocols such as Real-time Transport Protocol (RTP) \nomenclature{RTP}{Real-time Transport Protocol}, Real-time Transport Streaming Protocol (RTSP) \nomenclature{RTP}{Real-time Transport Streaming Protocol}, Session Description Protocol (SDP) \nomenclature{SDP}{Session Description Protocol} and Media Gateway Control Protocol (MEGACO) \nomenclature{MEGACO}{Media Gateway Control Protocol}.

SIP provides low level services to deliver messages between users, for example, it could deliver SDP messages to be negotiated between the endpoints in order to agree on the parameters of a session.

\begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{./figures/SIParchitecture.pdf}
      \caption[SIP session establishment example. Source~\cite{sipRFC}.]{SIP session establishment example. Source~\cite{sipRFC}.}
	\label{fig:SIParchitecture}
\end{figure}

Figure~\ref{fig:SIParchitecture} shows a typical example of a SIP scenario with a message exchange between two endpoints. SIP can use SDP Offer/Answer model for the session description or capabilities negotiation between the end-points~\cite{sdpIETF} and RTP for the media transport.

On the other side, SIP also relies on some elements called proxy servers that help to route requests to the final destination. Those proxies are represented in Figure~\ref{fig:SIParchitecture}.

SIP uses a wide range of methods that help the protocol to understand the type of message that is exchanging between peers. Figure~\ref{fig:SIParchitecture} shows an example of message exchange between endpoints. INVITE request is an indicator to the receiver that someone is trying to contact, Trying indicates that the INVITE has been received and the proxy is trying to find the correct path to the destination, Ringing message represents hold for answer from the other peer. Finally, once the receiver chooses to answer, an OK message is generated to indicate that the media session can start. 

The different media parameters are negotiated using the SDP bodies transmitted into the SIP methods previously mentioned. Those parameters are agreed between the peers in order to provide compatibility.

This protocol has been used for some time and improved due to many iterations and additions to itself. The knowledge raised from this technology helped to have a better understanding of the requirements when building real-time media protocols such as WebRTC.

\subsection{Real Time Media Flow Protocol (RTMFP) and Adobe Flash}

RTMFP  \nomenclature{RTMFP}{Real Time Media Flow Protocol} and Adobe Flash are proprietary technologies provided by Adobe, both services work together to deliver multimedia and RTC between users.

Adobe Flash is a media software that uses a plugin to work on top of the browser, it is used to build multimedia experiences for end users such as graphics, animation, games and Rich Internet Applications (RIA) \nomenclature{RIA}{Rich Internet Application}. It is widely used to stream video or audio in web applications, in order to enable this content we need to install Adobe Flash plugin on the computer. 

Adobe uses a proprietary programming language called JavaScript Flash Language (JSFL) \nomenclature{JSFL}{JavaScript Flash Language} and ActionScript. RTMFP and Adobe Flash require a plugin to work with any device, this obliges the user to install extra software that is not included in the browser, these two technologies are not standardized and are difficult to enable in some mobile devices. Flash Player is available for most platforms, except iOS devices, and is present in about 98\% of all Internet-enabled browser devices. This plugin allows developers to access media streams using external devices such as cameras and microphones to be used along with RTMFP.

This protocol is implemented by using Flash Player, Adobe Integrated Runtime (AIR) and Adobe Media Server (AMS) \nomenclature{AMS}{Adobe Media Server}~\cite{rtmfpDraft}. 

RTMFP uses Adobe Flash to provide media and data transfer between two end points over UDP~\cite{rtmfpDraft}. RTMFP requires a plugin to be installed in order to be functional being a proprietary protocol. It also handles congestion control over the path and NAT transversal issues. One of the biggest differences is that, compared to SIP, RTMFP does not provide inter-domain connectivity and both peers must be in the same working domain to be able to communicate.

Media transfer is encrypted, this feature is provided in RTMFP by using proprietary algorithms and different encryption methods. RTMFP architecture allows reconnection in case of connectivity issues and works multiplexing different media streams over the session. On the signaling part, Adobe uses an application server called Cirrus~\cite{cirrusFAQ} (Figure~\ref{fig:RTMFParchitecture}) to handle the signaling between the different participants of a session. This service provides support to handle different topologies such as: end-to-end, many-to-many and multicast. Those structures rely on the use of overlay techniques in multicast and mesh scenarios. 
 
 \begin{figure}[h]
  \centering
    \includegraphics[scale=0.4]{./figures/cirrusAdobe.pdf}
      \caption[RTMFP architecture using Cirrus]{RTMFP architecture using Cirrus.}
	\label{fig:RTMFParchitecture}
\end{figure}
 
One of the most valuable feature is the possibility to integrate P2P multicast topologies where one source sends a video to a group of receivers.

\subsection{Web Real-Time Communication (WebRTC)}

WebRTC is part of the HTML5 proposal, it is defined in the W3C~\cite{webrtcW3cgroup}~\cite{getusermediaDraft}, and enables RTC capabilities between Internet browsers using simple JavaScript APIs, providing video, audio and data P2P without the need of plugins. This API is in the process of replacing the need for installing a plugin to enable P2P communications between browsers, WebRTC uses existing standardized protocols to perform RTC. 

%The project was open sourced by Google to keep working with the IETF in order to standardize the technology~\cite{haraldpublicWebRTC}.

WebRTC provides interoperability between different browser vendors, this allow the APIs to be accessible by the developers assuring high degree of compatibility (Figure~\ref{fig:marketshare}). Some of the major browsers that include some WebRTC APIs are: Google Chrome, Mozilla Firefox and Opera. Other providers, such as Internet Explorer, are in process of building prototypes for WebRTC~\cite{IEwebRTC}. 

 \begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{./figures/marketshare}
      \caption[Market share of browser vendors by April 2013. Source~\cite{NetMarketShare}]{Market share of browser vendors by April 2013~\cite{NetMarketShare}.}
	\label{fig:marketshare}
\end{figure}

With WebRTC, developers can provide applications for most of the desktop devices available, mobile devices will integrate WebRTC as part of their HTML5 package to also enable RTC soon~\cite{ericssonbowser}.

WebRTC is composed of two important APIs that enable real-time features, GetUserMedia and PeerConnection. Both of them are accessible by JavaScript on the browser. 

%WebRTC APIs rely on the top of the {\it WebKit} rendering engine in Chrome and Opera, in April 2013 Google announced that is going to stop using {\it WebKit} as the rendering engine that is behind displaying web pages in Chrome. Instead, it's creating its own rendering engine named {\it Blink}~\cite{movingtoBlink}.
%It is able to solve NAT transversal environments by using a mixtures of ICE, TURN and STUN technologies. For the session description it uses a modified bundled version of SDP. The format used for packet transport is RTP and SRTP, modified WebSockets are in use for P2P DataChannel implementation to provide data transport multiplexed over the same stream. All the traffic is sent over UDP or TCP over the same port~\cite{alvestrandOverview2012}.
%
%WebRTC is part of the HTML5 package, both combined are an open cross-platform standard that aims to replace the Adobe proprietary proposal for P2P Real-Time Communication (RTC).
%
%By using HTML5 features we avoid the need of installing any extra software to be able to use real-time multimedia applications on the browser.

\subsubsection{GetUserMedia API}
\label{sec:gum}

WebRTC applications use the GetUserMedia API to allow access to media streams from local devices (video cameras and microphones). 

This API itself does not provide RTC, but provides the media to be used as simple HTML elements in any web application. 

{\it GetUserMedia} API allows developers to access local media devices using JavaScript code and generates media streams to be used either with the rest of the {\it PeerConnection} API or with the HTML5 video element for playback purposes~\cite{getusermediaDraft}. {\it GetUserMedia} is already interoperable between Google Chrome, Firefox and Opera~\cite{chromefirefoxinterop}.

{\it GetUserMedia} proposal removes the need for using Adobe Flash to access the media device and also the plugin requirement.

 \begin{figure}[h]
  \centering
    \includegraphics[scale=1]{./figures/mediastreamAPI.png}
      \caption[Media Stream object description. Source ~\cite{getusermediaDraft}]{Media Stream object description. Source~\cite{getusermediaDraft}.}
	\label{fig:mediastreamAPI}
\end{figure}

Figure~\ref{fig:mediastreamAPI} illustrates how the browser access the media and delivers the output to JavaScript. We use the {\it GetUserMedia} API to build WebRTC-enabled applications for RTC video conferencing. The video tag is an HTML5 Document Object Model (DOM) \nomenclature{DOM}{Document Object Model} element that reproduces local and remote media streams.

In Figure~\ref{fig:mediastreamAPI} {\it MediaStream} is the object returned by the {\it GetUserMedia} API methods, this object is contains {\it MediaStreamTracks} that carry the actual video and audio media. The goal of using this architecture is to be able, in the near future, to include multiple sources of video and audio multiplexed over the same stream from different devices. Different alternatives include the implementation of overlay topologies by forwarding media from one peer to the other by including different {\it MediaStreamTracks} into the same {\it MediaStream}. Furthermore, {\it MediaStreams} handle the synchronization between all the {\it MediaStreamTracks} included for proper playback at the application level, by this it assures that audio and video will be always synchronized.

{\it GetUserMedia} API works using a JavaScript fallback method, this method returns a {\it MediaStream} object to the application that is played in the HTML web application or used in the {\it PeerConnection} API. A sample example of this method can be seen in Listing~\ref{lst:listing1}.

\lstset{language=JavaScript}
\begin{lstlisting}[caption={Simple example of video and audio access using JavaScript},label={lst:listing1}]
GetUserMedia(cameraConstraints(), gotStream, function() {
	console.log("GetUserMedia failed");
});
    
function gotStream(stream) {
	//Stream is the MediaStream object returned by the API
	console.log("GetUserMedia succeeded");
  	document.getElementById("local-video").src = createObjectURL(stream);
}
\end{lstlisting}

In Listing~\ref{lst:listing1}, we are using the video and audio media from our devices to be played in an HTML video element identified as {\it local-video}. 

{\it GetUserMedia} API also allow developers to set some specific constraints for the media acquisition. This helps applications to better adapt the stream to their requirements, those {\it cameraConstraints()} are provided by a JavaScript Object Notation (JSON) \nomenclature{JSON}{JavaScript Object Notation} library.

\subsubsection{PeerConnection API}
\label{sec:pcAPI}

WebRTC uses a separate API to provide the networking support to transfer media and data to the other peers, this API is named {\it PeerConnection}~\cite{editorWebRTCdraft}. PeerConnection API bundles all the internal mechanisms of the browser that enable media and data transfer, at the same time it also handles all the exchange signaling messages with specific JavaScript methods. 

Figure~\ref{fig:webrtcExample} describes the topology used in WebRTC for a bi-directional media session, with the messages being sent either by WebSockets or by HTTP long polling. Messages are built using a modified bundled version of SDP, WebRTC signaling messages are similar to SIP as they use SDP bodies for the agreement.

%BUNDLED SDP AND SDP

SDP is widely used in SIP to provide media and NAT reversal negotiation between two different endpoints prior to establish data transmission. This protocol is used in WebRTC in a modified version that allow the usage of multiple media descriptions over a single set of Interactive Connectivity Establishment (ICE) \nomenclature{ICE}{Interactive Connectivity Establishment}. Usually, in other conditions, different media types will be described using different media descriptions.

This new feature is described as Bundle~\cite{SDPBUNDLE} and can be used along with the existing SDP Offer/Answer mechanism to negotiate the different media ("m=" lines) on the session.
%%

By using Bundled SDP, WebRTC multiplexes all the traffic using a single port, this means that media, data and monitoring messages are sent over the same port from peer to peer, traffic is sent over UDP or TCP~\cite{alvestrandOverview2012}. PeerConnection API provides signaling and NAT transversal techniques, this part is very important to guarantee a high degree of success when establishing calls in different environments.

{\it PeerConnection} P2P session establishment system works in a constrained environment designed to provide some degree of legacy for other SDP based technologies. Figure~\ref{fig:webrtcExample} shows how a WebRTC simple P2P scenario works, the server used for signaling is a web server. WebRTC scenarios do not work easily in a federated environment such as SIP.

On the other side, signaling is not standardized in WebRTC and has to be provided in the application level by the developer.

\lstset{language=JavaScript}
\begin{lstlisting}[caption=Simple example of {\it PeerConnection} using JavaScript,label={lst:listing2}]
//XXXX represents the stun server address
var pc_config = {"iceServers": [{"url": "stun:XXXX"}]};
pc = new webkitRTCPeerConnection(pc_config);
pc.onicecandidate = iceCallback1;

//Localstream is the local media obtained with the GetUserMedia API
pc.addStream(localstream);

function iceCallback1(event){
	if (event.candidate) {
		sendMessage(event.candidate);
	}
}

//When incoming candidate from the other peer we send it to the PeerConnection
pc.addIceCandidate(new RTCIceCandidate(event.candidate));

//This is fired when the remote media is received
pc.onaddstream = gotRemoteStream; 
function gotRemoteStream(e){
	document.getElementById("remote-video").src = URL.createObjectURL(e.stream);
}
\end{lstlisting}

Figure~\ref{fig:webrtcExample} does not show relay servers that provide NAT transversal solutions described in Section~\ref{sec:internals} . When developing a WebRTC application, those servers must be provided into the WebRTC {\it PeerConnection} configuration when starting a new call as seen in Listing~\ref{lst:listing2}.

 \begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{./figures/webrtcExample.pdf}
      \caption[WebRTC simple topology for P2P communication]{WebRTC simple topology for P2P communication.}
	\label{fig:webrtcExample}
\end{figure}

Listing~\ref{lst:listing2} represents a simple example of how to use the {\it PeerConnection} API to perform a P2P connection and start transferring media, this code works in conjunction with the code in section~\ref{sec:gum}. When building the new {\it PeerConnection} object we need to pass the JSON object {\it server} with the stun configuration for the NAT transversal process: {\it var pc\_config = \{"iceServers": [\{"url": "stun:XXXX"\}]\};}. 

\subsubsection{Control and Monitoring}
\label{sec:constraints}

Control and monitoring is an important part of all RTC protocols, this part is usually handled by the JavaScript API.

Media constraints are defined as a set of parameters that limit the media quality when processed from the devices such as microphone or webcam, those parameters are usually related to video size or frame rate in WebRTC. However, in WebRTC we can also adapt the maximum link rate through a special set of constraints.

Those parameters are implemented through the Statistics Model and Constraints defined in the W3C draft~\cite{editorWebRTCdraft}, these set of methods are part of the actual {\it PeerConnection} API defined in section~\ref{sec:pcAPI}. Once the {\it PeerConnection} is made and media is flowing we need to measure the quality of the connection, this is done by retrieving the stats provided in the Real Time Control Protocol (RTCP) \nomenclature{RTCP}{Real Time Control Protocol} messages that are being sent over the link form the remote side. We focus on those remote stats to study the status of the path and to obtain the desired metrics for monitoring~\cite{varunMetrics}. 

%The  Audio Video Profile with Feedback (AVPF) \nomenclature{AVPF}{Audio Video Profile with Feedback} provides significant improvements in the transmission of RTCP messages that are event driven rather than periodic~\cite{salvatore} like in other RTP based technologies.

To access the statistical data retrieved from the control messages we need to use the {\it getStats()} method of the {\it PeerConnection} object defined in the draft~\cite{editorWebRTCdraft}, this method allow the application to access that data in a JSON format that might require some post-processing. Statistical models are useful for the developers to monitor the status of their WebRTC applications and adjust the attributes of the {\it PeerConnection}. 

Within constraints, developers are able to change media capture configuration by setting parameters such as Frames per Second (FPS) \nomenclature{FPS}{Frames per Second} and video resolution. Other attributes can be set on the {\it PeerConnection} such as bandwidth requirements, transfer rate is automatically adjusted in WebRTC using its internal mechanisms but we can set a maximum value. 

JSON objects for camera and bandwidth constraints must be defined as in the following code.

\lstset{language=JavaScript}
\begin{lstlisting}[caption=JSON objects for constraints attributes in WebRTC]
//Media constraints in Pixels for Width and Height. Frames per Second in minFrameRate
var constraints = {
	"audio": true,
 	"video": {
  		"mandatory": {
   			"minWidth": "300",
   			"maxWidth": "640",
   			"minHeight": "200",
   			"maxHeight": "480",
   			"minFrameRate": "30"
  		},
  	"optional": []
 	}
}
//Bandwidth in kbps
var pc_constraints = {
	"mandatory": {},
 	"optional": [
 	 {
   		"bandwidth": "1000"
  	}
 	]
}
\end{lstlisting}

Both constraints objects are added to the {\it GetUserMedia} and {\it PeerConnection} methods when building the new session. Values are in pixels for the media attributes and Kbit/s for the rate configuration.

\subsubsection{Low vs High level API}

During the development of WebRTC there has been a lot of discussion in the different working groups about the API layout, those APIs have been designed using the feedback provided by the JavaScript developers.

One of the difficult parts in the standardization process has been to decide about the complexity level of the API, how much is available to be accessed by the developers and which configurations or mechanisms should be automated in the browser. After long discussion, WebRTC is now using Javascript Session Establishment Protocol (JSEP) \nomenclature{JSEP}{JavaScript Session Establishment Protocol}~\cite{jsepIETF}, this API is a low level API that gives the developers control of the signaling plane allowing each application to be used in specific environments.

% some applications give legacy to SIP or Jingle protocols meanwhile others might only work in a closed web domain. 

The media processing is done in the browser internals but most of the signaling is handled in the JavaScript plane by using JSEP methods and functions. Figure~\ref{fig:JSEP} shows the JSEP signaling model, this system extracts the signaling part leaving media transmission to the browser. However, JSEP provides mechanisms to create offers and answers, as well to apply them to a session. The way those messages are communicated to the remote side is left entirely up to the application.

Furthermore, JSEP also handles the state management of the session by building the specific SDP message that is forwarded to the other peer. NAT traversal mechanisms are activated in JSEP also, those mechanisms are described in chapter~\ref{sec:internals}.

%that provides the different candidates required by the other peer in order to build the connection, those mechanisms are defined in chapter~\ref{sec:internals}

Another interesting feature that JSEP provides is called {\it rehydration}, this process is used whenever a page that contains an existing WebRTC session is reloaded keeping the existing session alive. This technique avoid session cuts when accidentally reloading the page or with any automatic update from the web application. With {\it rehydration}, the current signaling state is stored somewhere outside the page, either on the server or in browser local storage~\cite{jsepIETF}.
 
 \begin{figure}[h]
  \centering
    \includegraphics[scale=0.9]{./figures/JSEP.pdf}
      \caption[JSEP signaling model]{JSEP signaling model.}
	\label{fig:JSEP}
\end{figure}

Low level APIs allow developers to build their own high level APIs that handle all the WebRTC protocol from media access to signaling. Those high level methods are useful to simplify the way JavaScript developers build their applications, building object oriented calls we can have JavaScript libraries that set up and maintain multiple calls at the same time. The benefits of having low level JSEP API for WebRTC is that there are the multiple possibilities to adapt WebRTC to the requirements of each specific application disregarding its advantages or disadvantages without being sensitive to pick one specific design at a time.

%We have developed our own high level API to create and handle RTC sessions and monitoring using WebRTC.

\subsubsection{Internals of WebRTC}
\label{sec:internals}

WebRTC has multiple internal mechanisms that enable the RTC in the browser level by using APIs. Those mechanisms work together to accomplish all the goals of WebRTC features, some of them are related to the network level and others to video access.

One of WebRTC main issues is NAT transversal difficulties, this problem usually affects all RTC related technologies. Interactive Connectivity Establishment (ICE) \nomenclature{ICE}{Interactive Connectivity Establishment} is a technique that helps WebRTC to decide which is the best way to bypass NATs and firewalls, ICE is widely used in media communications and has proven to be reliable when choosing the best option to enable connectivity in restrictive environments~\cite{iceIETF}.The enablers that work together with ICE for Real-time protocols are Simple Transversal Utilities for NAT (STUN) \nomenclature{STUN}{Simple Transversal Utilities for NAT} and Traversal Using Relays around NAT (TURN) \nomenclature{TURN}{Traversal Using Relays around NAT}~\cite{stunIETF}~\cite{turnIETF}.

TURN and STUN servers are usually placed outside the local network of the clients and help them to find the way to communicate with each other by discovering new open paths, the final decision is taken by the ICE mechanism. STUN server function is to discover the available IP addresses and ports that allow direct connectivity to a target machine placed behind a firewall or NAT, those interfaces are named {\it candidates}, this information is provided to the sender that processes it in order to choose the best {\it candidate}. On the other side, TURN works as a relay, this option should be always stated as the last resort when connection to no other {\it candidate} was established. TURNs work by rerouting the traffic from one peer to the other. 

All traffic in WebRTC is done over UDP and multiplexed over the same port. In case of TURN the traffic can be sent over TCP also.

Media encoding in WebRTC is done through codecs implemented inside the browser. Mandatory-to-Implement codecs for audio are G.711 and Opus. G.711 is an International Telecommunication Union (ITU) \nomenclature{ITU}{International Telecommunication Union} standard audio codec that has been used in multiple real time applications such as SIP. In real-time media applications, Opus is also a good alternative for G.711, Opus is a lossy audio compression format codec developed by the IETF and that is designed to work in real-time media applications on the Internet~\cite{opusIETF}. Opus can be easily adjusted for high and low encoding rates, applications can use additional codecs.

Along with the codecs, the audio engine for WebRTC also includes some features such as Acoustic Echo Cancellation (AEC) \nomenclature{AEC}{Acoustic Echo Cancellation} and Noise Reduction (NR) \nomenclature{NR}{Noise Reduction}. The first mechanism is a software based signal processing component that removes, in real time, the acoustic echo resulting from the voice being played out coming into the microphone (local loop), with this, WebRTC solves the issue of the audio loops with the output and input sound devices of computers. NR is a component that removes background noise associated to real time audio communications. When both mechanisms are working properly, the rate required by the audio channel is reduced as the unnecessary noise is removed from the spectrum. AEC and NR mechanisms provide a smooth audio input for WebRTC protocol.

%There has been a lot of discussion regarding video codec, two of the proposed codecs are H.264 and VP8. H.264 is a standard codec for video compression, this codec is widely used for recording and transmission of high definition video. Originally it was also selected due its high compatibility with existing devices and software, H.264 has made some controversy as it is patented and licensed by MPEG LA and may add some royalty problem for WebRTC. VP8 is a video compression codec owned by Google released and released in May 2010, VP8 is supported by Chrome, Opera and Firefox by default and is the de facto codec for WebRTC by May 2013. Later on, Google announced a VP8 patent cross-license agreement to provide royalty-free license to allow developers to implement VP8 video in their web applications~\cite{vp8Google}. This video codec is adaptive and performs well in low bandwidth links at the same time as providing royalty-free implementation.

WebRTC is not only useful for sending media, it can also provide P2P data transfer. This feature is named {\it Data Channel} and provides real time data transfer, this can be used with multiple purposes, from real time IM service to gaming, but it is interesting as {\it Data Channel} allows generic data exchange in a bidirectional way between two peers~\cite{datachanIETF}. Non-media data in WebRTC is transferred using System Control Transmission Protocol (SCTP) \nomenclature{SCTP}{System Control Transmission Protocol} encapsulated over Datagram Transport Layer Security (DTLS) \nomenclature{DTLS}{Datagram Transport Layer Security}~\cite{sctpIETF}~\cite{dtlsIETF}~\cite{datachanIETF}. 

The encapsulation of SCTP over DTLS on top of ICE/UDP provides a NAT traversal solution for data transfer that combines confidentiality, source authentication and integrity. This data transport service can operate in parallel with media transfer and is sent multiplexed over the same port. This feature of WebRTC is accessible from the JavaScript {\it PeerConnection} API by a combination of methods, functions and callbacks. 

%From the developer perspective, all the previous statements regarding security and transport are handled in the browser internals providing a simple and reliable way of sending P2P secure data over WebRTC.

WebRTC provides Secure Real-time Transport Protocol (SRTP) \nomenclature{SRTP}{Secure Real-time Transport Protocol} to allow media to be secured.The key-management for SRTP is provided by DTLS-SRTP which is an in-band keying and security parameter negotiation mechanism~\cite{salvatore}. Figure~\ref{fig:stack} illustrates the full protocol stack for WebRTC described in this chapter.

 \begin{figure}[h]
  \centering
    \includegraphics[scale=0.8]{./figures/protocolstack.pdf}
      \caption[WebRTC protocol stack. Source~\cite{salvatore}]{WebRTC protocol stack. Source~\cite{salvatore}.}
	\label{fig:stack}
\end{figure}

Quality of Service (QoS) \nomenclature{QoS}{Quality of Service} for WebRTC is also being discussed in the IETF and a draft is available with some proposals~\cite{qosWebRTCIETF}. WebRTC uses DiffServ packet marking for QoS but this is not sufficient to help prevent congestion in some environments. When using DiffServ, problems that arise are originated on the Internet Service Providers (ISPs) as they might be using their own packet marking with different DiffServ code-points, those packets are not interoperable between ISPs, there is an ongoing proposal to solve this problem by building consistent code-points~\cite{diffservIETF}. Otherwise, clients might also be sending too much data for the specified path reducing the effectiveness of DiffServ. Each specific application will mark Audio/video packets with the designed priority using DSCP mappings~\cite{qosWebRTCIETF}. 

Officially there is no congestion control mechanisms for WebRTC, the only mechanism actively used are circuit breakers for RTP~\cite{circuitbreakers}.

Furthermore, Chrome specifically uses a Google congestion control algorithm that enables congestion control mechanisms for rate adaptation~\cite{alvestrandCongestion2012}. The aim of this algorithm is to provide performance and bandwidth sharing with other ongoing conferences and applications that share the same link. This algorithm is defined in Section~\ref{sec:tests}.

%\subsection{Support}
%The following companies and organizations have supported and are actively working in the development of WebRTC standard in the W3C: Google, Mozilla and Opera~\cite{googleAnnouncement}. Other companies such as Microsoft have supported browser-to-browser solution but have published their own proposal which differs with the one published in the WebRTC WG, called CU-RTC-Web~\cite{curtcweb} which is a lower level API that claims to do everything that JSEP does.
%
%During the firsts attempts to build a reliable solution for WebRTC Ericsson Labs presented an initial API based on the preliminary work done in the WHATWG, this API was called ConnectionPeer API and required an special module to be installed in your browser~\cite{ericssonwebrtc}. Ericsson lately dropped from the effort to build it's own browser to focus in the standardization and codec discussion, leaving the API implementation to the Mozilla and Chrome teams. The original API evolved rapidly during the next months thanks to the WGs and the developer community feedback that is experimenting with the unstable API.
%
%%\subsection{Milestones}
%During the process of standardization some important moments should be remarked. In January 2012 Opera implemented the first version of WebRTC getUserMedia for accessing the camera and audio~\cite{operaannouncement}, during this year getUserMedia is available in the stable version of Opera. 
%
%Google Chrome integrated the first version of WebRTC in its DEV and Canary channels of the browser during January 2012~\cite{chromeannouncement}, in June 2012 it started moving its API to the stable channel hidden behind a flag, in November 2012 WebRTC becomes fully available in Google Chrome stable channel and is open for public usage~\cite{chromestable}. 
%
%Mozilla Firefox started working on the getUserMedia implementation early 2012 delivering the first version of media access trough API at the beginning of 2012 in the alpha version~\cite{mozillablog}, in April 2012 Mozilla published a WebRTC video demo running on Firefox in the "adler" channel~\cite{mozillawebrtc}, also supporting some primitive DataChannel API. Later in October Firefox Nightly was carrying the first unstable version of the WebRTC API including DataChannel~\cite{mozillafinal}, Mozilla announced in September 2012 that the stable version of WebRTC will be shipped along with Firefox 18 in January 2013~\cite{mozillacomming}, finally, the first public announcement of interoperability between Firefox and Chrome was done the 4th of February 2013~\cite{chromefirefoxinterop}.
%
%Some announcements done from Microsoft point out that they are also working in some implementation into Internet Explorer by using CU-RTC-Web as the default standard, at the moment only the Media API information is publicly available~\cite{microsoftcapture}.
%
%In October 2012 Ericsson announced the world's first WebRTC-enabled browser for mobile devices called "Bowser" with support for iOS and Android, this browser is able to handle WebRTC calls using RTCWeb Offer/Answer Protocol (ROAP) which is an old discontinued version of the WebRTC API that has moved to Javascript Session Establishment Protocol (JSEP). This browser also differs from the previous desktop alternatives on the codec side, it is carrying H.264 for video and G.711 for audio~\cite{ericssonbowser}. The API provided by Bowser is not fully W3C compliant.

%\subsection{Issues in WebRTC}
%
%WebRTC uses a mixture of different technologies to perform peer-to-peer communication between clients, those technologies range from SRTP, RTP, RTCP and multiple codecs that are being discussed. This scenario makes performance the key point for success in developing stable WebRTC applications. 
%
%Performance is manly related to computer capabilities and the ability to encode/decode at the same time as transferring and monitoring multiple peer connections. All those tasks are run over the browser and not directly on the OS, this is good for interoperability between platforms but bad in the performance aspect. Compared to Adobe technologies which uses a plugin, the performance they can deliver should be higher as they do not use as many application layers.
%
%Media applications are delay sensitive and require a low packet loss for its proper function, WebRTC is working on this aspect by trying to implement congestion control over the connection stablished between peers, this work is not completed yet and will arise as a problem in the near future. Packet loss due to system capacity and bandwidth are measurable in WebRTC using the Stats API, this API provides information about the PeerConnection performance and is accessible by JavaScript.
%
%Media constraints and bandwidth statistics will make a big difference in how media is acquired in WebRTC. Browsers and web applications have always tolerate some amount of delay and packet losses but this is not possible in media infrastructures for real time applications, an effort is needed to handle Quality of Service (QoS) in WebRTC to compete with RTMFP.

%\subsubsection{Quality of Service}
%
%Quality of Service (QoS) for WebRTC is being discussed and an internet draft is available with some proposals~\cite{qosWebRTCIETF}. WebRTC uses DiffServ packet marking for QoS but this is not sufficient to help prevent congestion in some environments. When using DiffServ the problem arises from the Internet Service Providers (ISPs) as they might be using their own packet marking with different DiffServ code-points, those won't be interoperability between ISPs, there is an ongoing proposal to build consistent code-points. Audio/video packets will be marked as priority using DSCP mappings with audio being more important than video or data~\cite{qosWebRTCIETF}. 
%
%The possibility to combine QoS in the transport layer with the constraints and stats of the WebRTC API will help developers to build more adaptive applications, for example, lowing the Frames per Second (FPS) in the case of high packet losses will reduce the bandwidth usage in the case of congestion of the link. This is possible thanks to the Stats API that provide the data statistics for the peer connection.
%
%Some environments will also require better QoS as their bandwidth will be lower, examples in the use case draft relate this to surveillance cameras or similar approaches~\cite{WebRTCcasesIETF}. In these cases QoS should be modified by using the API, this situation can lead also to malicious JavaScript injection that could flood the path with packets. 

\subsubsection{Security concerns}

To handle the signaling process WebRTC uses a web application server, peers exchange messages with each other through the web server in multiple different ways. By using this system WebRTC provides high flexibility for developers to allow multiple scenarios, on the other side, it also has some important security concerns~\cite{WebRTCcasesIETF}. Figure~\ref{fig:webrtcExample} presents a simple topology for a WebRTC call, the web application server handles the signaling messages to the peers and the media transport is done between them and provided by the browser.

Obviously, this system poses a range of new security and privacy challenges different from traditional VoIP systems. Considering that WebRTC APIs are able to bypass Firewalls and NAT, Denial of Services (DoS) \nomenclature{DoS}{Denial of Service} attacks can also become a threat. On the other side, malicious JavaScripts could also perform calling to unknown devices.

Browsers execute JavaScript scripts provided by the web applications, this may include malicious scripts, that in the case of WebRTC could lead to some privacy issues. In a WebRTC environment, we consider the browser to be a trusted unit and the JavaScript provided by the server to be unknown as it could execute a variety of actions in that browser. At a minimum, it should not be possible for arbitrary sites to initiate calls to arbitrary locations without user apprehension~\cite{rtcwebSecurityIETF}. To approach this issue, the user must make the decision to allow a call (and the access to its webcam media) with previous knowledge of who is requesting the access, where the media is going or both.

% \begin{figure}[h]
%  \centering
%    \includegraphics[scale=0.9]{./figures/xss.pdf}
%      \caption[Example of cross-site scripting attack]{Example of cross-site scripting attack.}
%	\label{fig:xss}
%\end{figure}

In web services, issues such as Cross-site scripting (XSS) \nomenclature{XSS}{Cross-site scripting} provide high risk of privacy vulnerability~\cite{crosssitescripting}. Those situations are given when a third-party server provides JavaScript scripts to a different domain to the one accessed. This script cannot be trusted by the original accessed domain as it could trigger browser actions that might harm privacy. For example, in WebRTC, the user could load a malicious script from a third-party entity in order to automatically build a WebRTC call to an undesired receiver without the user noticing this situation. Nowadays, browsers provide some degree of protection against XSS and do not let some scripting actions to be performed.

Other related vulnerabilities in WebRTC APIs include the possibility to establish media forwarding to a third peer, for example, once the user has accepted the access to the media, the provided JavaScript could build one {\it PeerConnection} to the receiver and an extra one to a remote peer that could store the call without the user noticing this behavior. Those problems are not only related to WebRTC and tend to happen in related protocols.

 \begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{./figures/idpWebRTCcall.pdf}
      \caption[WebRTC cross-domain call with Identity Provider authentication]{WebRTC cross-domain call with Identity Provider authentication.}
	\label{fig:idpWebRTCcall}
\end{figure}

Calling procedure is done using the JavaScript provided by the server, this may be a problem as the user must trust an unknown authority provider. WebRTC calling services usually rely on Hypertext Transfer Protocol Secure (HTTPS) \nomenclature{HTTPS}{Hypertext Transfer Protocol Secure} for authentication where the origin can be verified and users are verified cryptographically (DTLS-SRTP). Browser peers should be authorized before starting the media flow, this can be done by the {\it PeerConnection} itself using some Identity Provider (IdP) that supports OpenID or BrowserID to demonstrate their identity~\cite{rtcwebSecurityArchIETF}. Usually this problem is not particularly important in a closed domain, cases where both peers are in the same social network and provide their profiles to the system, those are exchanged previous to the call, but it arises as a big issue when having federated calls from different domains such in Figure~\ref{fig:idpWebRTCcall}.

If the web service is running over a trusted secure certificate and has authorized access to the media, {\it GetUserMedia} access becomes automatic after the first time under the same domain, otherwise, the user has to verify the access for each call. Once the media is acquired, the API builds the ICE candidates for media verification. Authentication and verification in WebRTC is an ongoing discussion in the working groups.

Security and privacy issues in WebRTC can be given in multiple layers of the protocol, the increment of trust for the provider gives some vulnerability issues that sometimes cannot be easily solved if the aim is to keep a flexible and open sourced real time protocol. Some use cases for WebRTC also incorporate some level of vulnerability as the JavaScript is going to be provided by a third-party, in the use case of media streaming, advertisement or call centers where service providers could pick data form the users and store them for further usage~\cite{WebRTCcasesIETF}.

\subsection{Comparison between SIP, RTMFP and WebRTC}

After describing various RTC technologies and two important alternatives for WebRTC, Table~\ref{fig:CompareRTC} is a summary of common features between SIP, RTMFP and WebRTC. In this Table~\ref{fig:CompareRTC}, common internal mechanisms are described for all of them.

\begin{table}[h]
\begin{center}
	\begin{tabular}{| l | c | c | c |}
	\hline
    	 & SIP & RTMFP & WebRTC \\ \hline
    	Plugin-enabled & No &Yes & No \\ \hline
    	Cross-domain & Yes & No & Maybe \\ \hline
    	%Android & Yes & Yes & Yes \\ \hline
    	%iOS & Yes & No & Yes \\ \hline
    	Audio & Yes & Yes & Yes \\ \hline
    	Video & Yes & Yes & Yes \\ \hline
    	Data & Yes & No & Yes \\ \hline
	NAT Traversal & Yes & Yes & Yes \\ \hline
	\hline \hline
	TURN & Yes & No & Yes \\ \hline
    	STUN & Yes & No & Yes \\ \hline
    	SDP & Yes & No & Yes \\ \hline
    	RTP & Yes & No & Yes \\ \hline
    	SRTP & Yes & No & Yes \\ \hline
    	UDP & Yes & Yes & Yes \\ \hline
    	TCP & Yes & No & Yes \\ \hline
    	SCTP & Yes & No & Yes \\ \hline
	\end{tabular}
      \caption[Features comparison between SIP, RTMFP and WebRTC]{Features comparison between SIP, RTMFP and WebRTC.}
	\label{fig:CompareRTC}
\end{center}
\end{table}

RTFMP is a proprietary protocol which means that it might have its own mechanisms other than the standardized ones stated on Table~\ref{fig:CompareRTC} to solve some of the issues.

All the protocols explained in this section are designed to provide similar real time features but in different ways, meanwhile SIP is a protocol that helped to develop some of the important technologies, such as RTP and SRTP, that are used in other technologies, is still not easily accessible for web developers. On the other side, RTMFP provides a licensed alternative for real time communication having some mechanisms not standardized and with compatibility issues between devices.

From the mobile perspective, SIP is used in mobile technology and WebRTC has announced to be compatible with future versions of iOS and Android~\cite{ericssonbowser}. Furthermore, RTMFP has active support for Android but is still not able to extend its usage to iOS platforms.

All three protocols provide NAT traversal solutions but RTMFP is the only one that provides a proprietary solution for NAT traversal that is not standardized, SIP and WebRTC use a conjunction of TURN, STUN and ICE mechanisms.
	
All of them are valid options, in this thesis we basically work with WebRTC and its related mechanisms.	

\subsection{Summary}

We can conclude that real-time media protocols have been developed over quite a long period. However, a standardized open source solution has not been provided yet.  WebRTC and SIP share a basement of principles that work together, we could state that WebRTC could not exist as it is now without the previous knowledge provided by SIP. Besides, the usability of SIP in web applications is still very complex and prohibitive for most web developers.

Furthermore, RTMFP has shown more ubiquitous availability on user's devices than any specific web browser. The main problem with RTMFP approach is that the protocol for end-to-end media path is proprietary, so interoperating with existing VoIP solutions can be inefficient and developers rely on vendor's plugins to take care of any platform incompatibilities.

WebRTC solution may not be perfect but is a good start to provide interoperable real-time solution for web applications.